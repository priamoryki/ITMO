{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn import metrics\n",
    "import tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Модель"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 13 * 13, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Функция обучения"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def test(model, test_dataloader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_predictions = []\n",
    "    test_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "\n",
    "            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()\n",
    "            test_predictions.append(output.data.max(1)[1])\n",
    "            test_targets.append(target)\n",
    "\n",
    "    test_predictions = torch.cat(test_predictions).cpu()\n",
    "    test_targets = torch.cat(test_targets).cpu()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "\n",
    "    test_accuracy = metrics.accuracy_score(test_targets, test_predictions)\n",
    "    test_precision = metrics.precision_score(test_targets, test_predictions, average=\"macro\", zero_division=0)\n",
    "\n",
    "    return test_loss, test_accuracy, test_precision\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, epochs=5):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    iteration, log_interval = 1, 10_000 // batch_size\n",
    "\n",
    "    train_losses, test_losses, train_accuracies, test_accuracies, test_precisions = [], [], [], [], []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}\")\n",
    "        print(\"-------------------------------\")\n",
    "        model.train()\n",
    "        train_loss_epoch = []\n",
    "        train_predictions = []\n",
    "        train_targets = []\n",
    "        for batch, (data, target) in enumerate(train_dataloader):\n",
    "            # Train single batch\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            train_loss_epoch.append(loss.data.item())\n",
    "            optimizer.step()\n",
    "            train_predictions.append(output.data.max(1)[1])\n",
    "            train_targets.append(target)\n",
    "\n",
    "            if iteration % log_interval == 0:\n",
    "                test_loss, test_accuracy, test_precision = test(model, test_dataloader)\n",
    "                model.train()\n",
    "                train_losses.append(loss.data.item())\n",
    "                l = np.mean(train_loss_epoch)\n",
    "                train_loss_epoch = []\n",
    "                test_losses.append(test_loss)\n",
    "                test_accuracies.append(test_accuracy)\n",
    "                test_precisions.append(test_precision)\n",
    "\n",
    "                train_predictions = torch.cat(train_predictions).cpu()\n",
    "                train_targets = torch.cat(train_targets).cpu()\n",
    "                acc = metrics.accuracy_score(train_targets, train_predictions)\n",
    "                train_predictions, train_targets = [], []\n",
    "                train_accuracies.append(acc)\n",
    "                print(\n",
    "                    f\"{(batch + 1) * len(data):>5d}/{len(train_dataloader.dataset):>5d} | train_loss: {l:>5f} | train accuracy: {acc:>4f} | accuracy: {test_accuracy:>4f}\")\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "    return train_losses, test_losses, test_accuracies, test_precisions, train_accuracies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Создаем тренировочный и тестовый датасеты"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "mnist_training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "mnist_test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "epochs, batch_size = 6, 100\n",
    "mnist_train_dataloader = DataLoader(mnist_training_data, batch_size=batch_size, shuffle=True)\n",
    "mnist_test_dataloader = DataLoader(mnist_test_data, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Обучение Mnist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.762698 | train accuracy: 0.754800 | accuracy: 0.951900\n",
      "20000/60000 | train_loss: 0.292527 | train accuracy: 0.910000 | accuracy: 0.958600\n",
      "30000/60000 | train_loss: 0.250663 | train accuracy: 0.926600 | accuracy: 0.971500\n",
      "40000/60000 | train_loss: 0.215386 | train accuracy: 0.935500 | accuracy: 0.966900\n",
      "50000/60000 | train_loss: 0.203999 | train accuracy: 0.940900 | accuracy: 0.968400\n",
      "60000/60000 | train_loss: 0.209140 | train accuracy: 0.940500 | accuracy: 0.973500\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.187973 | train accuracy: 0.942900 | accuracy: 0.978700\n",
      "20000/60000 | train_loss: 0.178187 | train accuracy: 0.947000 | accuracy: 0.974700\n",
      "30000/60000 | train_loss: 0.174164 | train accuracy: 0.948500 | accuracy: 0.980200\n",
      "40000/60000 | train_loss: 0.173066 | train accuracy: 0.949700 | accuracy: 0.978400\n",
      "50000/60000 | train_loss: 0.175725 | train accuracy: 0.949500 | accuracy: 0.972700\n",
      "60000/60000 | train_loss: 0.170425 | train accuracy: 0.950600 | accuracy: 0.979000\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.155674 | train accuracy: 0.954400 | accuracy: 0.975400\n",
      "20000/60000 | train_loss: 0.158582 | train accuracy: 0.953100 | accuracy: 0.978300\n",
      "30000/60000 | train_loss: 0.160481 | train accuracy: 0.952000 | accuracy: 0.982600\n",
      "40000/60000 | train_loss: 0.158048 | train accuracy: 0.954300 | accuracy: 0.980000\n",
      "50000/60000 | train_loss: 0.167002 | train accuracy: 0.950800 | accuracy: 0.982700\n",
      "60000/60000 | train_loss: 0.154356 | train accuracy: 0.955000 | accuracy: 0.977600\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.161135 | train accuracy: 0.953900 | accuracy: 0.983700\n",
      "20000/60000 | train_loss: 0.148173 | train accuracy: 0.958800 | accuracy: 0.982100\n",
      "30000/60000 | train_loss: 0.148492 | train accuracy: 0.954600 | accuracy: 0.979700\n",
      "40000/60000 | train_loss: 0.168764 | train accuracy: 0.951700 | accuracy: 0.981400\n",
      "50000/60000 | train_loss: 0.143258 | train accuracy: 0.960400 | accuracy: 0.982200\n",
      "60000/60000 | train_loss: 0.146349 | train accuracy: 0.958900 | accuracy: 0.982500\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.140960 | train accuracy: 0.960600 | accuracy: 0.981400\n",
      "20000/60000 | train_loss: 0.153117 | train accuracy: 0.954700 | accuracy: 0.981600\n",
      "30000/60000 | train_loss: 0.147422 | train accuracy: 0.956200 | accuracy: 0.984500\n",
      "40000/60000 | train_loss: 0.143959 | train accuracy: 0.957200 | accuracy: 0.982500\n",
      "50000/60000 | train_loss: 0.138301 | train accuracy: 0.959600 | accuracy: 0.982000\n",
      "60000/60000 | train_loss: 0.135200 | train accuracy: 0.961300 | accuracy: 0.982700\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.154643 | train accuracy: 0.956200 | accuracy: 0.983800\n",
      "20000/60000 | train_loss: 0.147244 | train accuracy: 0.957800 | accuracy: 0.973000\n",
      "30000/60000 | train_loss: 0.144856 | train accuracy: 0.961200 | accuracy: 0.977900\n",
      "40000/60000 | train_loss: 0.139480 | train accuracy: 0.958600 | accuracy: 0.982600\n",
      "50000/60000 | train_loss: 0.142635 | train accuracy: 0.961000 | accuracy: 0.982100\n",
      "60000/60000 | train_loss: 0.150110 | train accuracy: 0.958600 | accuracy: 0.983700\n"
     ]
    }
   ],
   "source": [
    "model_mnist = MnistModel()\n",
    "train_losses, test_losses, test_accuracies, test_precisions, train_accuracies = train(\n",
    "    model_mnist,\n",
    "    mnist_train_dataloader,\n",
    "    mnist_test_dataloader,\n",
    "    epochs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "torch.save(model_mnist.state_dict(), \"models/mnist.torch\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/mnist\")\n",
    "for i in range(len(test_losses)):\n",
    "    writer.add_scalar(\"Train loss\", train_losses[i], i)\n",
    "    writer.add_scalar(\"Test loss\", test_losses[i], i)\n",
    "    writer.add_scalar(\"Test accuracy\", test_accuracies[i], i)\n",
    "    writer.add_scalar(\"Test precisions\", test_precisions[i], i)\n",
    "    writer.add_scalar(\"Train accuracy\", train_accuracies[i], i)\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Создаем тренировочный и тестовый датасеты"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "fashion_training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "fashion_test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "epochs, batch_size = 6, 100\n",
    "fashion_train_dataloader = DataLoader(fashion_training_data, batch_size=batch_size, shuffle=True)\n",
    "fashion_test_dataloader = DataLoader(fashion_test_data, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Обучение Fashion MNIST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.856991 | train accuracy: 0.704800 | accuracy: 0.823700\n",
      "20000/60000 | train_loss: 0.545447 | train accuracy: 0.809500 | accuracy: 0.854600\n",
      "30000/60000 | train_loss: 0.474532 | train accuracy: 0.831200 | accuracy: 0.856500\n",
      "40000/60000 | train_loss: 0.447456 | train accuracy: 0.836300 | accuracy: 0.866300\n",
      "50000/60000 | train_loss: 0.431988 | train accuracy: 0.848100 | accuracy: 0.857400\n",
      "60000/60000 | train_loss: 0.417572 | train accuracy: 0.850100 | accuracy: 0.874100\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.390538 | train accuracy: 0.856100 | accuracy: 0.863700\n",
      "20000/60000 | train_loss: 0.393894 | train accuracy: 0.855600 | accuracy: 0.857800\n",
      "30000/60000 | train_loss: 0.404803 | train accuracy: 0.849300 | accuracy: 0.875100\n",
      "40000/60000 | train_loss: 0.391039 | train accuracy: 0.860300 | accuracy: 0.886300\n",
      "50000/60000 | train_loss: 0.394838 | train accuracy: 0.856300 | accuracy: 0.871600\n",
      "60000/60000 | train_loss: 0.391175 | train accuracy: 0.859100 | accuracy: 0.883500\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.374835 | train accuracy: 0.862200 | accuracy: 0.880400\n",
      "20000/60000 | train_loss: 0.380634 | train accuracy: 0.861300 | accuracy: 0.882600\n",
      "30000/60000 | train_loss: 0.371017 | train accuracy: 0.867800 | accuracy: 0.879200\n",
      "40000/60000 | train_loss: 0.368820 | train accuracy: 0.863300 | accuracy: 0.868000\n",
      "50000/60000 | train_loss: 0.363408 | train accuracy: 0.865300 | accuracy: 0.886100\n",
      "60000/60000 | train_loss: 0.361267 | train accuracy: 0.868700 | accuracy: 0.890900\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.345417 | train accuracy: 0.875400 | accuracy: 0.886800\n",
      "20000/60000 | train_loss: 0.356171 | train accuracy: 0.869900 | accuracy: 0.882100\n",
      "30000/60000 | train_loss: 0.364204 | train accuracy: 0.865600 | accuracy: 0.874300\n",
      "40000/60000 | train_loss: 0.379542 | train accuracy: 0.860000 | accuracy: 0.885300\n",
      "50000/60000 | train_loss: 0.347332 | train accuracy: 0.874800 | accuracy: 0.887800\n",
      "60000/60000 | train_loss: 0.365918 | train accuracy: 0.869500 | accuracy: 0.888400\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.348810 | train accuracy: 0.874300 | accuracy: 0.886100\n",
      "20000/60000 | train_loss: 0.358321 | train accuracy: 0.871300 | accuracy: 0.877400\n",
      "30000/60000 | train_loss: 0.355102 | train accuracy: 0.870500 | accuracy: 0.887000\n",
      "40000/60000 | train_loss: 0.358687 | train accuracy: 0.869600 | accuracy: 0.885300\n",
      "50000/60000 | train_loss: 0.349907 | train accuracy: 0.873900 | accuracy: 0.886000\n",
      "60000/60000 | train_loss: 0.357125 | train accuracy: 0.866900 | accuracy: 0.892000\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.321797 | train accuracy: 0.882100 | accuracy: 0.880600\n",
      "20000/60000 | train_loss: 0.368836 | train accuracy: 0.863700 | accuracy: 0.879300\n",
      "30000/60000 | train_loss: 0.346725 | train accuracy: 0.871700 | accuracy: 0.888200\n",
      "40000/60000 | train_loss: 0.353386 | train accuracy: 0.869300 | accuracy: 0.888000\n",
      "50000/60000 | train_loss: 0.371026 | train accuracy: 0.862300 | accuracy: 0.884200\n",
      "60000/60000 | train_loss: 0.365462 | train accuracy: 0.868500 | accuracy: 0.885200\n"
     ]
    }
   ],
   "source": [
    "model_fashion = MnistModel()\n",
    "train_losses, test_losses, test_accuracies, test_precisions, train_accuracies = train(\n",
    "    model_fashion,\n",
    "    fashion_train_dataloader,\n",
    "    fashion_test_dataloader,\n",
    "    epochs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/fashion\")\n",
    "for i in range(len(test_losses)):\n",
    "    writer.add_scalar(\"Train loss\", train_losses[i], i)\n",
    "    writer.add_scalar(\"Test loss\", test_losses[i], i)\n",
    "    writer.add_scalar(\"Test accuracy\", test_accuracies[i], i)\n",
    "    writer.add_scalar(\"Test precisions\", test_precisions[i], i)\n",
    "    writer.add_scalar(\"Train accuracy\", train_accuracies[i], i)\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Дообучение Fashion MNIST с помощью MNIST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 1.555941 | train accuracy: 0.492000 | accuracy: 0.745300\n",
      "20000/60000 | train_loss: 0.792950 | train accuracy: 0.698300 | accuracy: 0.790300\n",
      "30000/60000 | train_loss: 0.684770 | train accuracy: 0.739200 | accuracy: 0.800500\n",
      "40000/60000 | train_loss: 0.625312 | train accuracy: 0.759600 | accuracy: 0.818500\n",
      "50000/60000 | train_loss: 0.576647 | train accuracy: 0.777300 | accuracy: 0.833300\n",
      "60000/60000 | train_loss: 0.554149 | train accuracy: 0.791600 | accuracy: 0.839200\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.544152 | train accuracy: 0.794000 | accuracy: 0.838000\n",
      "20000/60000 | train_loss: 0.532387 | train accuracy: 0.803700 | accuracy: 0.842800\n",
      "30000/60000 | train_loss: 0.503077 | train accuracy: 0.811100 | accuracy: 0.845000\n",
      "40000/60000 | train_loss: 0.512161 | train accuracy: 0.806900 | accuracy: 0.854000\n",
      "50000/60000 | train_loss: 0.505193 | train accuracy: 0.808500 | accuracy: 0.833300\n",
      "60000/60000 | train_loss: 0.487198 | train accuracy: 0.818700 | accuracy: 0.847600\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.484755 | train accuracy: 0.822000 | accuracy: 0.853500\n",
      "20000/60000 | train_loss: 0.489917 | train accuracy: 0.811800 | accuracy: 0.843900\n",
      "30000/60000 | train_loss: 0.454983 | train accuracy: 0.831800 | accuracy: 0.854700\n",
      "40000/60000 | train_loss: 0.468711 | train accuracy: 0.821400 | accuracy: 0.866800\n",
      "50000/60000 | train_loss: 0.460831 | train accuracy: 0.832600 | accuracy: 0.864000\n",
      "60000/60000 | train_loss: 0.445660 | train accuracy: 0.831700 | accuracy: 0.864100\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.436388 | train accuracy: 0.833100 | accuracy: 0.868000\n",
      "20000/60000 | train_loss: 0.427204 | train accuracy: 0.840500 | accuracy: 0.862700\n",
      "30000/60000 | train_loss: 0.442095 | train accuracy: 0.833200 | accuracy: 0.869200\n",
      "40000/60000 | train_loss: 0.446351 | train accuracy: 0.832500 | accuracy: 0.869500\n",
      "50000/60000 | train_loss: 0.453608 | train accuracy: 0.834900 | accuracy: 0.864800\n",
      "60000/60000 | train_loss: 0.447678 | train accuracy: 0.839200 | accuracy: 0.869600\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.435139 | train accuracy: 0.836900 | accuracy: 0.867000\n",
      "20000/60000 | train_loss: 0.429179 | train accuracy: 0.840000 | accuracy: 0.866800\n",
      "30000/60000 | train_loss: 0.423894 | train accuracy: 0.840300 | accuracy: 0.866900\n",
      "40000/60000 | train_loss: 0.430280 | train accuracy: 0.840300 | accuracy: 0.874200\n",
      "50000/60000 | train_loss: 0.415309 | train accuracy: 0.845700 | accuracy: 0.866100\n",
      "60000/60000 | train_loss: 0.435826 | train accuracy: 0.839500 | accuracy: 0.860000\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.439722 | train accuracy: 0.839100 | accuracy: 0.866300\n",
      "20000/60000 | train_loss: 0.429834 | train accuracy: 0.839400 | accuracy: 0.869100\n",
      "30000/60000 | train_loss: 0.402920 | train accuracy: 0.851700 | accuracy: 0.871400\n",
      "40000/60000 | train_loss: 0.425514 | train accuracy: 0.840000 | accuracy: 0.867100\n",
      "50000/60000 | train_loss: 0.417522 | train accuracy: 0.849500 | accuracy: 0.870200\n",
      "60000/60000 | train_loss: 0.430214 | train accuracy: 0.840200 | accuracy: 0.877600\n"
     ]
    }
   ],
   "source": [
    "fashion_continue_model = MnistModel()\n",
    "fashion_continue_model.load_state_dict(torch.load(\"models/mnist.torch\"))\n",
    "train_losses, test_losses, test_accuracies, test_precisions, train_accuracies = train(\n",
    "    fashion_continue_model,\n",
    "    fashion_train_dataloader,\n",
    "    fashion_test_dataloader,\n",
    "    epochs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/fashion_continue\")\n",
    "for i in range(len(test_losses)):\n",
    "    writer.add_scalar(\"Train loss\", train_losses[i], i)\n",
    "    writer.add_scalar(\"Test loss\", test_losses[i], i)\n",
    "    writer.add_scalar(\"Test accuracy\", test_accuracies[i], i)\n",
    "    writer.add_scalar(\"Test precisions\", test_precisions[i], i)\n",
    "    writer.add_scalar(\"Train accuracy\", train_accuracies[i], i)\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Дообучение Fashion MNIST с помощью MNIST с заморозкой свёрточных слоёв"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_freeze_model = MnistModel()\n",
    "fashion_freeze_model.load_state_dict(torch.load(\"models/mnist.torch\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_model.0.weight      True\n",
      "_model.0.bias        True\n",
      "_model.2.weight      True\n",
      "_model.2.bias        True\n",
      "_model.7.weight      True\n",
      "_model.7.bias        True\n",
      "_model.10.weight     True\n",
      "_model.10.bias       True\n"
     ]
    }
   ],
   "source": [
    "for name, param in fashion_freeze_model.named_parameters():\n",
    "    print(f\"{name:<20s} {param.requires_grad}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "freeze_params = [\n",
    "    \"_model.0.weight\",\n",
    "    \"_model.0.bias\",\n",
    "    \"_model.2.weight\",\n",
    "    \"_model.2.bias\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "for name, param in fashion_freeze_model.named_parameters():\n",
    "    if name in freeze_params:\n",
    "        param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_model.0.weight      False\n",
      "_model.0.bias        False\n",
      "_model.2.weight      False\n",
      "_model.2.bias        False\n",
      "_model.7.weight      True\n",
      "_model.7.bias        True\n",
      "_model.10.weight     True\n",
      "_model.10.bias       True\n"
     ]
    }
   ],
   "source": [
    "for name, param in fashion_freeze_model.named_parameters():\n",
    "    print(f\"{name:<20s} {param.requires_grad}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 1.644562 | train accuracy: 0.481200 | accuracy: 0.717800\n",
      "20000/60000 | train_loss: 0.952638 | train accuracy: 0.640800 | accuracy: 0.754500\n",
      "30000/60000 | train_loss: 0.820286 | train accuracy: 0.684600 | accuracy: 0.731200\n",
      "40000/60000 | train_loss: 0.787053 | train accuracy: 0.701200 | accuracy: 0.774100\n",
      "50000/60000 | train_loss: 0.755027 | train accuracy: 0.707800 | accuracy: 0.784600\n",
      "60000/60000 | train_loss: 0.719157 | train accuracy: 0.722900 | accuracy: 0.793500\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.698781 | train accuracy: 0.729100 | accuracy: 0.799100\n",
      "20000/60000 | train_loss: 0.699909 | train accuracy: 0.732000 | accuracy: 0.800600\n",
      "30000/60000 | train_loss: 0.658780 | train accuracy: 0.749800 | accuracy: 0.782700\n",
      "40000/60000 | train_loss: 0.675029 | train accuracy: 0.742000 | accuracy: 0.798100\n",
      "50000/60000 | train_loss: 0.658215 | train accuracy: 0.753200 | accuracy: 0.809700\n",
      "60000/60000 | train_loss: 0.639818 | train accuracy: 0.753600 | accuracy: 0.815800\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.645356 | train accuracy: 0.754500 | accuracy: 0.809300\n",
      "20000/60000 | train_loss: 0.637567 | train accuracy: 0.756200 | accuracy: 0.817900\n",
      "30000/60000 | train_loss: 0.631363 | train accuracy: 0.755800 | accuracy: 0.812900\n",
      "40000/60000 | train_loss: 0.599379 | train accuracy: 0.774100 | accuracy: 0.818500\n",
      "50000/60000 | train_loss: 0.627391 | train accuracy: 0.760800 | accuracy: 0.813300\n",
      "60000/60000 | train_loss: 0.610168 | train accuracy: 0.765400 | accuracy: 0.818100\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, test_accuracies, test_precisions, train_accuracies = train(\n",
    "    fashion_freeze_model,\n",
    "    fashion_train_dataloader,\n",
    "    fashion_test_dataloader,\n",
    "    epochs // 2\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/fashion_freeze\")\n",
    "for i in range(len(test_losses)):\n",
    "    writer.add_scalar(\"Train loss\", train_losses[i], i)\n",
    "    writer.add_scalar(\"Test loss\", test_losses[i], i)\n",
    "    writer.add_scalar(\"Test accuracy\", test_accuracies[i], i)\n",
    "    writer.add_scalar(\"Test precisions\", test_precisions[i], i)\n",
    "    writer.add_scalar(\"Train accuracy\", train_accuracies[i], i)\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Дообучение Fashion MNIST с помощью MNIST с разморозкой свёрточных слоёв"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "for name, param in fashion_freeze_model.named_parameters():\n",
    "    if name in freeze_params:\n",
    "        param.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_model.0.weight      True\n",
      "_model.0.bias        True\n",
      "_model.2.weight      True\n",
      "_model.2.bias        True\n",
      "_model.7.weight      True\n",
      "_model.7.bias        True\n",
      "_model.10.weight     True\n",
      "_model.10.bias       True\n"
     ]
    }
   ],
   "source": [
    "for name, param in fashion_freeze_model.named_parameters():\n",
    "    print(f\"{name:<20s} {param.requires_grad}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.626990 | train accuracy: 0.768100 | accuracy: 0.828200\n",
      "20000/60000 | train_loss: 0.587343 | train accuracy: 0.781700 | accuracy: 0.830400\n",
      "30000/60000 | train_loss: 0.567347 | train accuracy: 0.784400 | accuracy: 0.834800\n",
      "40000/60000 | train_loss: 0.549700 | train accuracy: 0.788100 | accuracy: 0.835400\n",
      "50000/60000 | train_loss: 0.574835 | train accuracy: 0.779900 | accuracy: 0.826900\n",
      "60000/60000 | train_loss: 0.557465 | train accuracy: 0.790300 | accuracy: 0.838800\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.537068 | train accuracy: 0.795500 | accuracy: 0.849800\n",
      "20000/60000 | train_loss: 0.547438 | train accuracy: 0.792200 | accuracy: 0.837200\n",
      "30000/60000 | train_loss: 0.510699 | train accuracy: 0.808200 | accuracy: 0.850600\n",
      "40000/60000 | train_loss: 0.492890 | train accuracy: 0.817000 | accuracy: 0.854500\n",
      "50000/60000 | train_loss: 0.503728 | train accuracy: 0.814200 | accuracy: 0.845700\n",
      "60000/60000 | train_loss: 0.504108 | train accuracy: 0.814600 | accuracy: 0.858400\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "10000/60000 | train_loss: 0.485553 | train accuracy: 0.818900 | accuracy: 0.859900\n",
      "20000/60000 | train_loss: 0.495104 | train accuracy: 0.810300 | accuracy: 0.857500\n",
      "30000/60000 | train_loss: 0.486218 | train accuracy: 0.821200 | accuracy: 0.855200\n",
      "40000/60000 | train_loss: 0.478627 | train accuracy: 0.822300 | accuracy: 0.856300\n",
      "50000/60000 | train_loss: 0.478515 | train accuracy: 0.826700 | accuracy: 0.850700\n",
      "60000/60000 | train_loss: 0.487467 | train accuracy: 0.820600 | accuracy: 0.852900\n"
     ]
    }
   ],
   "source": [
    "train_losses_2, test_losses_2, test_accuracies_2, test_precisions_2, train_accuracies_2 = train(\n",
    "    fashion_freeze_model,\n",
    "    fashion_train_dataloader,\n",
    "    fashion_test_dataloader,\n",
    "    epochs // 2\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "train_losses.extend(train_losses_2)\n",
    "test_losses.extend(test_losses_2)\n",
    "test_accuracies.extend(test_accuracies_2)\n",
    "test_precisions.extend(test_precisions_2)\n",
    "train_accuracies.extend(train_accuracies_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/fashion_freeze_unfreeze\")\n",
    "for i in range(len(test_losses)):\n",
    "    writer.add_scalar(\"Train loss\", train_losses[i], i)\n",
    "    writer.add_scalar(\"Test loss\", test_losses[i], i)\n",
    "    writer.add_scalar(\"Test accuracy\", test_accuracies[i], i)\n",
    "    writer.add_scalar(\"Test precisions\", test_precisions[i], i)\n",
    "    writer.add_scalar(\"Train accuracy\", train_accuracies[i], i)\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-c5fb536dff21a47c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-c5fb536dff21a47c\");\n          const url = new URL(\"/\", window.location);\n          const port = 13000;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-2ab18f672cfae427\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-2ab18f672cfae427\");\n          const url = new URL(\"/\", window.location);\n          const port = 13001;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-d0a0bee068a1541d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-d0a0bee068a1541d\");\n          const url = new URL(\"/\", window.location);\n          const port = 13002;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-5389bd602827f24a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-5389bd602827f24a\");\n          const url = new URL(\"/\", window.location);\n          const port = 13003;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-5ebe285289e170b0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-5ebe285289e170b0\");\n          const url = new URL(\"/\", window.location);\n          const port = 13004;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs/mnist --port 20000\n",
    "%tensorboard --logdir runs/fashion --port 20001\n",
    "%tensorboard --logdir runs/fashion_continue --port 20002\n",
    "%tensorboard --logdir runs/fashion_freeze --port 20003\n",
    "%tensorboard --logdir runs/fashion_freeze_unfreeze --port 20004"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "colab": {
   "name": "Lab-1.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
